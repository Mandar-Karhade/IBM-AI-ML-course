{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare algorithms\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "import os \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "os.chdir(\"C:\\\\Users\\\\manka\\\\Documents\\\\GitHub\\\\Machine-learning-quickbook\")\n",
    "\n",
    "ind = ['cap-shape','cap-surface','cap-color','bruises','odor','gill-attachment',\n",
    "       'gill-spacing','gill-size','gill-color','stalk-shape','stalk-root',\n",
    "       'stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring',\n",
    "       'stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type',\n",
    "       'spore-print-color','population','habitat']\n",
    "dep = 'class'\n",
    "\n",
    "names = ind.append(dep)\n",
    "dataset = pd.read_csv(\"mushrooms.csv\")\n",
    "\n",
    "dataset = dataset.sample(500)\n",
    "dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Describe independent and dependent variables\n",
    "\n",
    "def insert_section(n=2):\n",
    "    print('\\n'*n)\n",
    "    print('-----------------------------------------------')\n",
    "\n",
    "def samplesize(dataset, n=1000):\n",
    "    if dataset.shape[0] > n :\n",
    "        sample=n\n",
    "    else :\n",
    "        sample = dataset.shape[0]\n",
    "    return sample\n",
    "\n",
    "def get_label_info(dataset, varlist):\n",
    "    # Get cardinality of each variable \n",
    "    for var in varlist:\n",
    "        print('\\n\\n')\n",
    "        print(\"Number of levels in category '{0}': \\b {1:2.2f} \".format(var, dataset[var].unique().size))\n",
    "        if dataset[var].unique().size < 10 :\n",
    "                print(\"Levels for catgeory '{0}': {1}\".format(var, dataset[var].unique()))\n",
    "\n",
    "\n",
    "def encode_decode_frame(data):\n",
    "    from collections import defaultdict\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    encoder_dict = defaultdict(LabelEncoder)\n",
    "    encoded_data = data.apply(lambda x: encoder_dict[x.name].fit_transform(x))\n",
    "\n",
    "    inverse_transform_lambda = lambda x: encoder_dict[x.name].inverse_transform(x)\n",
    "    labeled_data = encoded_data.apply(inverse_transform_lambda)\n",
    "    \n",
    "    return encoded_data, labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EDA\n",
    "display(print('Display datatypes of the data'))\n",
    "display(dataset.dtypes)\n",
    "\n",
    "display(print('Null profile of the data below'))\n",
    "display(dataset.isnull().sum())\n",
    "\n",
    "display(insert_section())\n",
    "\n",
    "get_label_info(dataset, ind)\n",
    "\n",
    "n = samplesize(dataset,1000)\n",
    "print(n)\n",
    "\n",
    "# report\n",
    "# profile = ProfileReport(dataset.sample(n))\n",
    "# profile.to_file(\"report.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding TPOT methods for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPOT to use for real dataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "# define dataset\n",
    "X = dataset[ind]\n",
    "Y = dataset[dep]\n",
    "\n",
    "# Encoding the dataframe's predictors\n",
    "encoded_x, decoded_x = encode_decode_frame(X)\n",
    "\n",
    "# train-test split using encoded X variable\n",
    "train_x, test_x, train_y, test_y = train_test_split( encoded_x.values, Y.values, test_size=0.20, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=1)\n",
    "\n",
    "# define search\n",
    "model = TPOTClassifier(generations=100, population_size=500, cv=cv\n",
    "                       , scoring='f1', verbosity=2, random_state=1\n",
    "                       , n_jobs=-1, early_stop=2)\n",
    "\n",
    "\n",
    "# perform the search\n",
    "model.fit(train_x, train_y)\n",
    "print(model.score(test_x, test_y))\n",
    "\n",
    "\n",
    "# export the best model\n",
    "model.export('tpot_best_model.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding manual methods of testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "array = dataset.values\n",
    "X = dataset[ind]\n",
    "Y = dataset[dep]\n",
    "train_x, test_x, train_y, test_y = train_test_split( X.values, Y.values, test_size=0.20, random_state=1, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot Check Algorithms (manual process)\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = StratifiedKFold(n_splits=20, random_state=1, shuffle=True)\n",
    "\tcv_results = cross_val_score(model, train_x, train_y, cv=kfold, scoring='accuracy')\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    "\n",
    "\n",
    "# Compare Algorithms\n",
    "pyplot.boxplot(results, labels=names)\n",
    "pyplot.title('Algorithm Comparison')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Good way of handling the data \n",
    "import timeit, os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as mpl\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, LabelEncoder, normalize\n",
    "from sklearn.impute import SimpleImputer \n",
    "from tpot import TPOTRegressor, TPOTClassifier\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Load dataset\n",
    "os.chdir(\"C:\\\\Users\\\\manka\\\\Documents\\\\GitHub\\\\Machine-learning-quickbook\")\n",
    "ind = ['cap-shape','cap-surface','cap-color','bruises','odor','gill-attachment',\n",
    "       'gill-spacing','gill-size','gill-color','stalk-shape','stalk-root',\n",
    "       'stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring',\n",
    "       'stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type',\n",
    "       'spore-print-color','population','habitat']\n",
    "dep = ['class']\n",
    "\n",
    "dataset = pd.read_csv(\"mushrooms.csv\")\n",
    "\n",
    "X = dataset.reindex(columns=[x for x in dataset.columns.values if x != 'class'])        # separate out X\n",
    "y = dataset.reindex(columns=['class'])  # separate out y\n",
    "\n",
    "X = dataset.reindex(columns=ind)        # separate out X\n",
    "y = dataset.reindex(columns=dep)        # separate out y\n",
    "# y = np.ravel(y)                         # flatten the y array\n",
    "\n",
    "# make list of numeric and string columns\n",
    "numeric_cols = [] # could still have ordinal data\n",
    "string_cols = []  # could have ordinal or nominal data\n",
    "\n",
    "for col in X.columns:\n",
    "    if (X.dtypes[col] == np.int64 or X.dtypes[col] == np.int32 or X.dtypes[col] == np.float64):\n",
    "        numeric_cols.append(col)      # True integer or float columns\n",
    "    \n",
    "    if (X.dtypes[col] == np.object):  # Nominal and ordinal columns\n",
    "        string_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with string variables (simplest form of imputation for missing as acreating a new label)\n",
    "X_string = X[string_cols]\n",
    "X_string = X_string.fillna(\"missing\")\n",
    "X_string = X_string.apply(LabelEncoder().fit_transform)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with numeric variables\n",
    "n_imputer = SimpleImputer(missing_values='NaN', copy = True, strategy = 'most_frequent') # imputing with most frequent because some of these numeric columns are ordinal\n",
    "\n",
    "X_numeric = X[numeric_cols]\n",
    "\n",
    "if X_numeric.shape[1] > 0:\n",
    "    X_numeric = n_imputer.fit_transform(X_numeric)\n",
    "    X_numeric = pd.DataFrame(X_numeric, columns = numeric_cols)\n",
    "else:\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 22 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   cap-shape                 8124 non-null   object\n",
      " 1   cap-surface               8124 non-null   object\n",
      " 2   cap-color                 8124 non-null   object\n",
      " 3   bruises                   8124 non-null   object\n",
      " 4   odor                      8124 non-null   object\n",
      " 5   gill-attachment           8124 non-null   object\n",
      " 6   gill-spacing              8124 non-null   object\n",
      " 7   gill-size                 8124 non-null   object\n",
      " 8   gill-color                8124 non-null   object\n",
      " 9   stalk-shape               8124 non-null   object\n",
      " 10  stalk-root                8124 non-null   object\n",
      " 11  stalk-surface-above-ring  8124 non-null   object\n",
      " 12  stalk-surface-below-ring  8124 non-null   object\n",
      " 13  stalk-color-above-ring    8124 non-null   object\n",
      " 14  stalk-color-below-ring    8124 non-null   object\n",
      " 15  veil-type                 8124 non-null   object\n",
      " 16  veil-color                8124 non-null   object\n",
      " 17  ring-number               8124 non-null   object\n",
      " 18  ring-type                 8124 non-null   object\n",
      " 19  spore-print-color         8124 non-null   object\n",
      " 20  population                8124 non-null   object\n",
      " 21  habitat                   8124 non-null   object\n",
      "dtypes: object(22)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   class   8124 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 63.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[5, 2, 4, ..., 2, 3, 5],\n",
       "       [5, 2, 9, ..., 3, 2, 1],\n",
       "       [0, 2, 8, ..., 3, 2, 3],\n",
       "       ...,\n",
       "       [2, 2, 4, ..., 0, 1, 2],\n",
       "       [3, 3, 4, ..., 7, 4, 2],\n",
       "       [5, 2, 4, ..., 4, 1, 2]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8124, 22)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8124,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirm encoded data types\n",
    "display(X.info())\n",
    "display(y.info())\n",
    "\n",
    "# Finalizaing encoced X and Y matrix\n",
    "y_encoded = LabelEncoder().fit_transform(np.ravel(y)) # Need to ravel to make (1,) matrix\n",
    "\n",
    "X = pd.concat([X_numeric, X_string], axis=1)\n",
    "X_encoded = X.values\n",
    "\n",
    "# View encoded data \n",
    "display(X_encoded)\n",
    "display(y_encoded)\n",
    "display(X_encoded.shape)\n",
    "display(y_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 2, 2, ..., 7, 4, 4],\n",
       "       [5, 3, 9, ..., 1, 5, 0],\n",
       "       [5, 0, 3, ..., 1, 5, 1],\n",
       "       ...,\n",
       "       [2, 3, 3, ..., 1, 5, 4],\n",
       "       [5, 3, 9, ..., 1, 5, 0],\n",
       "       [5, 3, 7, ..., 1, 4, 0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train test splot using only encoded X and Y matrix\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size = .25, random_state = 55)\n",
    "\n",
    "display(X_train)\n",
    "display(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b1d22e10fe49ef93d8e4a7f0ba2c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=25250.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 1.0\n",
      "Generation 2 - Current best internal CV score: 1.0\n",
      "Generation 3 - Current best internal CV score: 1.0\n",
      "Generation 4 - Current best internal CV score: 1.0\n",
      "Generation 5 - Current best internal CV score: 1.0\n",
      "Generation 6 - Current best internal CV score: 1.0\n",
      "The optimized pipeline was not improved after evaluating 5 more generations. Will end the optimization process.\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: KNeighborsRegressor(input_matrix, n_neighbors=1, p=1, weights=distance)\n"
     ]
    }
   ],
   "source": [
    "# instantiate tpot \n",
    "tpot = TPOTRegressor(verbosity=2,  \n",
    "                    random_state=1, \n",
    "                    scoring='f1',\n",
    "                    periodic_checkpoint_folder=\"intermediate_results\",\n",
    "                    n_jobs=5, \n",
    "                    warm_start = False,\n",
    "                    generations=100, \n",
    "                    population_size=250,\n",
    "                    early_stop=5)\n",
    "times = []\n",
    "scores = []\n",
    "winning_pipes = []\n",
    "\n",
    "# run 2 iterations\n",
    "for x in range(1):\n",
    "    start_time = timeit.default_timer()\n",
    "    tpot.fit(X_train, y_train)\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    times.append(elapsed)\n",
    "    winning_pipes.append(tpot.fitted_pipeline_)\n",
    "    scores.append(tpot.score(X_test, y_test))\n",
    "    tpot.export(str(x)+'_tpot_reg.py')\n",
    "\n",
    "# output results\n",
    "# times = [time/60 for time in times]\n",
    "# print('Times:', times)\n",
    "# print('Scores:', scores)   \n",
    "# print('Winning pipelines:', winning_pipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ce3725c35c43b2b1e47caef2eb8837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=500.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# instantiate tpot \n",
    "tpot = TPOTClassifier(verbosity=2,\n",
    "                      random_state=1,\n",
    "                      scoring='f1',\n",
    "                      periodic_checkpoint_folder=\"intermediate_results\",\n",
    "                      n_jobs=5,\n",
    "                      warm_start = False,\n",
    "                      generations=100, \n",
    "                      population_size=250,\n",
    "                      early_stop=5)\n",
    "times = []\n",
    "scores = []\n",
    "winning_pipes = []\n",
    "\n",
    "# run 2 iterations\n",
    "for x in range(1):\n",
    "    start_time = timeit.default_timer()\n",
    "    tpot.fit(X_train, y_train)\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    times.append(elapsed)\n",
    "    winning_pipes.append(tpot.fitted_pipeline_)\n",
    "    scores.append(tpot.score(X_test, y_test))\n",
    "    tpot.export(str(x)+'_tpot_clf.py')\n",
    "\n",
    "# output results\n",
    "times = [time/60 for time in times]\n",
    "print('Times:', times)\n",
    "print('Scores:', scores)   \n",
    "print('Winning pipelines:', winning_pipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average CV score on the training set was: 1.0\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "exported_pipeline = RandomForestClassifier(bootstrap=False, criterion=\"entropy\", max_features=0.3, min_samples_leaf=13, min_samples_split=19, n_estimators=100)\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(exported_pipeline, 'random_state'):\n",
    "    setattr(exported_pipeline, 'random_state', 1)\n",
    "\n",
    "exctracted_best_model = tpot.fitted_pipeline_.steps[-1][1]\n",
    "\n",
    "exported_pipeline.fit(X_train, y_train)\n",
    "results = exported_pipeline.predict(X_test)\n",
    "\n",
    "exctracted_best_model.feature_importances_\n",
    "\n",
    "# plot feature importance \n",
    "c = sns.color_palette(\"muted\", 3)[2]\n",
    "sns.barplot(x=X.columns.values, y=exctracted_best_model.feature_importances_, color=c)\n",
    "mpl.xticks(rotation=90)\n",
    "mpl.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
